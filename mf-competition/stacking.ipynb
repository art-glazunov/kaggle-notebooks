{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Реализация рабочего алгоритма стекинга по схеме 1 \n(по материалам А. Дьяконова)\n\nРазработал Глазунов А.В."},{"metadata":{},"cell_type":"markdown","source":"В данном ноутбуке я попробовал собрать основные рабочие моменты, касающиеся стекинга, которые помогли мне получить хорошие результаты на соревновании. Особенность стекинга в его устойчивости как к изменчивости данных, так и к слабым местам отдельных алгоритмов. В связи с использование множества разных моделей, стекинг показывает себя достаточно устойчивым алгоритмом. Если где-то есть неточности в коде, не судите строго, потому что оформлял ноутбук впопыхах, поскольку пришлось переносить из Google Colab и наводить красоту."},{"metadata":{},"cell_type":"markdown","source":"Нейросетевая библиотека для табличных данных на архитектуре трансформеров."},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install pytorch-tabnet","execution_count":2,"outputs":[{"output_type":"stream","text":"Collecting pytorch-tabnet\n  Downloading pytorch_tabnet-1.2.0-py3-none-any.whl (21 kB)\nRequirement already satisfied: torch<2.0,>=1.2 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet) (1.6.0)\nRequirement already satisfied: scipy>1.4 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet) (1.4.1)\nRequirement already satisfied: scikit_learn>0.21 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet) (0.23.2)\nRequirement already satisfied: tqdm<5.0,>=4.36 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet) (4.45.0)\nRequirement already satisfied: numpy<2.0,>=1.17 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet) (1.18.5)\nRequirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch<2.0,>=1.2->pytorch-tabnet) (0.18.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit_learn>0.21->pytorch-tabnet) (2.1.0)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit_learn>0.21->pytorch-tabnet) (0.14.1)\nInstalling collected packages: pytorch-tabnet\nSuccessfully installed pytorch-tabnet-1.2.0\n","name":"stdout"}]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":3,"outputs":[{"output_type":"stream","text":"/kaggle/input/mf-accelerator/contest_test.csv\n/kaggle/input/mf-accelerator/sample_subm.csv\n/kaggle/input/mf-accelerator/contest_train.csv\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.metrics import f1_score,classification_report\nfrom catboost import CatBoostClassifier,CatBoostRegressor\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.base import BaseEstimator, ClassifierMixin\n\nfrom sklearn.model_selection import cross_val_predict\n\nimport itertools\nfrom tqdm import tqdm_notebook\nimport gc\n\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.neighbors import KNeighborsClassifier\nimport lightgbm as lgb\n\nfrom sklearn.linear_model import Lasso\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\n\n\nfrom pytorch_tabnet.tab_model import TabNetRegressor\nimport torch\nimport warnings\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.ensemble import RandomForestRegressor","execution_count":4,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Загрузка данных и подготовка обучения и валидации"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/mf-accelerator/contest_train.csv')\ntarget = data.TARGET\ndata = data.fillna(0)","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = data.drop(columns=[\"TARGET\",\"ID\"])\nfeatures.head()","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"   FEATURE_0  FEATURE_1  FEATURE_2  FEATURE_3  FEATURE_4  FEATURE_5  \\\n0        2.0        2.0        0.0        0.0        0.0        0.0   \n1        1.0        1.0        0.0        0.0        1.0        0.0   \n2        0.0        0.0        0.0        0.0        0.0        0.0   \n3        1.0        1.0        0.0        0.0        0.0        0.0   \n4        4.0        3.0        1.0        0.0        1.0        0.0   \n\n   FEATURE_6   FEATURE_7  FEATURE_8  FEATURE_9  ...  FEATURE_250  FEATURE_251  \\\n0        0.0 -114.527812 -17.218055        0.0  ...         39.0          2.0   \n1        0.0  329.828334   0.000000        3.0  ...         25.0         82.0   \n2        0.0   17.427338  -6.680747        0.0  ...        119.0          0.0   \n3        0.0   23.621397  36.659534        0.0  ...          1.0          0.0   \n4        0.0  677.745861   0.000000        3.0  ...         21.0          0.0   \n\n   FEATURE_252  FEATURE_253  FEATURE_254  FEATURE_255  FEATURE_256  \\\n0   223.118594   290.015143          1.0          1.0          0.0   \n1   479.616045   611.651594          0.0          1.0          0.0   \n2   352.268014   564.573421          1.0          1.0          0.0   \n3   410.524985   421.653876          1.0          0.0          0.0   \n4   439.171356   476.189288          1.0          1.0          0.0   \n\n   FEATURE_257  FEATURE_258  FEATURE_259  \n0          1.0          2.0          2.0  \n1          1.0          1.0          1.0  \n2          1.0          1.0          1.0  \n3          1.0          2.0          2.0  \n4          1.0          1.0          1.0  \n\n[5 rows x 260 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>FEATURE_0</th>\n      <th>FEATURE_1</th>\n      <th>FEATURE_2</th>\n      <th>FEATURE_3</th>\n      <th>FEATURE_4</th>\n      <th>FEATURE_5</th>\n      <th>FEATURE_6</th>\n      <th>FEATURE_7</th>\n      <th>FEATURE_8</th>\n      <th>FEATURE_9</th>\n      <th>...</th>\n      <th>FEATURE_250</th>\n      <th>FEATURE_251</th>\n      <th>FEATURE_252</th>\n      <th>FEATURE_253</th>\n      <th>FEATURE_254</th>\n      <th>FEATURE_255</th>\n      <th>FEATURE_256</th>\n      <th>FEATURE_257</th>\n      <th>FEATURE_258</th>\n      <th>FEATURE_259</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-114.527812</td>\n      <td>-17.218055</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>39.0</td>\n      <td>2.0</td>\n      <td>223.118594</td>\n      <td>290.015143</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>329.828334</td>\n      <td>0.000000</td>\n      <td>3.0</td>\n      <td>...</td>\n      <td>25.0</td>\n      <td>82.0</td>\n      <td>479.616045</td>\n      <td>611.651594</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>17.427338</td>\n      <td>-6.680747</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>119.0</td>\n      <td>0.0</td>\n      <td>352.268014</td>\n      <td>564.573421</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>23.621397</td>\n      <td>36.659534</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>410.524985</td>\n      <td>421.653876</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>677.745861</td>\n      <td>0.000000</td>\n      <td>3.0</td>\n      <td>...</td>\n      <td>21.0</td>\n      <td>0.0</td>\n      <td>439.171356</td>\n      <td>476.189288</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 260 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_test = pd.read_csv('/kaggle/input/mf-accelerator/contest_test.csv')\nfeatures_test = data_test.copy().drop(columns=[\"ID\"])\nfeatures_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features_train,features_val,labels_train,labels_val = train_test_split(features,target, test_size = 0.3,\\\n                                                                   shuffle=True,random_state=1,\\\n                                                                   stratify = target)\nfeatures_train.head()","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"       FEATURE_0  FEATURE_1  FEATURE_2  FEATURE_3  FEATURE_4  FEATURE_5  \\\n554          1.0        1.0        0.0        0.0        0.0        0.0   \n21387        2.0        1.0        0.0        0.0        1.0        0.0   \n6718         0.0        0.0        0.0        0.0        0.0        0.0   \n20866        0.0        0.0        0.0        0.0        0.0        0.0   \n15346       23.0        3.0        0.0        0.0        0.0        0.0   \n\n       FEATURE_6   FEATURE_7    FEATURE_8  FEATURE_9  ...  FEATURE_250  \\\n554          0.0    9.730839   -10.974399        0.0  ...          1.0   \n21387        0.0  648.091341  4114.326196        2.0  ...         51.0   \n6718         0.0   58.794073    84.509810        0.0  ...          0.0   \n20866        0.0   66.619672   -28.118250        0.0  ...          0.0   \n15346        0.0   -8.098236     7.934105        0.0  ...          0.0   \n\n       FEATURE_251  FEATURE_252  FEATURE_253  FEATURE_254  FEATURE_255  \\\n554            3.0   131.152992   142.081810          1.0          0.0   \n21387        315.0   249.456205   598.692247          1.0          1.0   \n6718           0.0    35.496364    -9.022701          0.0          0.0   \n20866          3.0    63.459627    46.488404          1.0          1.0   \n15346         30.0   310.012449   437.498733          0.0          0.0   \n\n       FEATURE_256  FEATURE_257  FEATURE_258  FEATURE_259  \n554            0.0          2.0          1.0          1.0  \n21387          0.0          2.0          1.0          1.0  \n6718           0.0          1.0          1.0          1.0  \n20866          0.0          1.0          1.0          1.0  \n15346          0.0          1.0          1.0          1.0  \n\n[5 rows x 260 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>FEATURE_0</th>\n      <th>FEATURE_1</th>\n      <th>FEATURE_2</th>\n      <th>FEATURE_3</th>\n      <th>FEATURE_4</th>\n      <th>FEATURE_5</th>\n      <th>FEATURE_6</th>\n      <th>FEATURE_7</th>\n      <th>FEATURE_8</th>\n      <th>FEATURE_9</th>\n      <th>...</th>\n      <th>FEATURE_250</th>\n      <th>FEATURE_251</th>\n      <th>FEATURE_252</th>\n      <th>FEATURE_253</th>\n      <th>FEATURE_254</th>\n      <th>FEATURE_255</th>\n      <th>FEATURE_256</th>\n      <th>FEATURE_257</th>\n      <th>FEATURE_258</th>\n      <th>FEATURE_259</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>554</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>9.730839</td>\n      <td>-10.974399</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>131.152992</td>\n      <td>142.081810</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>21387</th>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>648.091341</td>\n      <td>4114.326196</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>51.0</td>\n      <td>315.0</td>\n      <td>249.456205</td>\n      <td>598.692247</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>6718</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>58.794073</td>\n      <td>84.509810</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>35.496364</td>\n      <td>-9.022701</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>20866</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>66.619672</td>\n      <td>-28.118250</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>63.459627</td>\n      <td>46.488404</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>15346</th>\n      <td>23.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-8.098236</td>\n      <td>7.934105</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>30.0</td>\n      <td>310.012449</td>\n      <td>437.498733</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 260 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Написание основных классов для работы стекинга"},{"metadata":{"trusted":true},"cell_type":"code","source":"class Stacking(BaseEstimator, ClassifierMixin):  \n    \"\"\"Стекинг моделей \n    на основе материалов А. Дьяконова\n    \"\"\"\n    \n\n    def __init__(self, models, metamodel,merge=False):\n        \"\"\"\n        Инициализация\n        models - базовые модели для стекинга\n        metamodel - метамодель\n        \"\"\"\n        self.models = models\n        self.metamodel = metamodel\n        self.n = len(models)\n        self.meta = None\n        self.merge = merge\n\n\n    def fit(self, X, y=None, p=0.25, random_state=0):\n        \"\"\"\n        Обучение стекинга\n\n        p - в каком отношении делить на выборку \n        на подвыборки для базовых и метаалгоритма\n        random_state - для воспроизводимости\n        merge - слить полученные признаки и исходные при работе метаалгоритма    \n        \"\"\"\n        # разбиение на обучение моделей и метамодели\n        base, meta, y_base, y_meta = train_test_split(X, y, test_size=p, random_state=random_state,stratify = y)\n            \n        # заполнение матрицы для обучения метамодели\n        self.meta = np.zeros((meta.shape[0], self.n))\n        for t, base_model in enumerate(self.models):\n            base_model.fit(np.array(base), np.array(y_base))\n                \n            self.meta[:, t] = base_model.predict(meta).reshape((1,-1))#reshape для работы нейросетей и катбуста\n            print(f\"Ok {t}\")\n\n        # обучение метамодели\n        if self.merge:#если обучаем метамодель на объединенной выборке с исходными признаками и новыми\n            data_meta_ext = np.concatenate((meta,self.meta),axis=1)\n            self.metamodel.fit(data_meta_ext, y_meta)\n        else:\n            self.metamodel.fit(self.meta, y_meta)\n        print(\"------\")\n        print(\"Ok\")\n\n\n        return self\n    \n\n\n    def predict(self, X, y=None):\n        \"\"\"\n        Предсказание стекингом\n        \"\"\"\n        # заполение матрицы для мета-классификатора\n        X_meta = np.zeros((X.shape[0], self.n))\n        \n        print(\"------\")\n        print(\"Prediction\")  \n\n\n\n        for t, base_model in enumerate(self.models):\n            \n            X_meta[:, t] = base_model.predict(X).reshape((1,-1))\n          \n            print(f\"Ok{t}\")  \n          \n\n        if self.merge:#если объединенная выборка для обучения метамодели\n            data_meta_test = np.concatenate((X,X_meta),axis=1)\n            res = self.metamodel.predict(data_meta_test)\n\n        else:\n            res = self.metamodel.predict(X_meta)\n        \n        return (res)","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class NNWrapper(BaseEstimator, ClassifierMixin):  \n    \"\"\"Обертка для нейросетей для совместимости со стекингом\"\"\"\n\n    def __init__(self, model,scaler,X_valid=None,\n                 y_valid=None,max_epochs=10, patience=150):\n        \n        self.model = model\n        self.X_valid = X_valid\n        self.y_valid = y_valid\n        self.max_epochs = max_epochs\n        self.patience = patience\n        self.scaler = scaler\n\n    def fit(self, X, y=None):\n        X_sc = self.scaler.fit_transform(X)\n        self.model.fit(X_train=np.array(X_sc), y_train=np.array(y), X_valid=self.X_valid,y_valid=self.y_valid,\n                  max_epochs=self.max_epochs, patience=self.patience) \n\n        return self\n\n    def predict(self, X_test, y=None):\n        X_test_sc = self.scaler.transform(np.array(X_test))\n        prediction = self.model.predict(np.array(X_test_sc)).reshape((1,-1))#Ключевая строка\n        \n        \n        return prediction\n\nclass LMWrapper(BaseEstimator, ClassifierMixin):  \n    \"\"\"Обертка для линейных и иных простых моделей \n    для использования масштабирования\"\"\"\n\n    def __init__(self, model,scaler):\n        \n        self.model = model\n        self.scaler = scaler\n        \n    def fit(self, X, y=None):\n        \n        X_sc = self.scaler.fit_transform(X)\n        self.model.fit(X_sc, y) \n\n        return self\n\n    def predict(self, X_test, y=None):\n        X_test_sc = self.scaler.transform(X_test)\n        prediction = self.model.predict(X_test_sc)\n        \n        \n        return prediction","execution_count":10,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Задание моделей, которые будут работать в качестве базовых для реализации стекинга. Обратите внимание, что, несмотря на задачу классификации, среди базовых моделей много регрессоров, так мы получаем более разнообразные и качественные метапризнаки."},{"metadata":{"trusted":true},"cell_type":"code","source":"ls0 = Lasso(alpha=0.01,random_state=0)\nknn1 = LMWrapper(KNeighborsRegressor(n_neighbors=3,),StandardScaler())\nknn2 = LMWrapper(KNeighborsRegressor(n_neighbors=10),StandardScaler())\nrf2 = RandomForestRegressor(n_estimators=100, max_depth=10,random_state=100)\ngbm1 = lgb.LGBMRegressor(boosting_type='gbdt', learning_rate=0.05, max_depth=7, n_estimators=200, nthread=-1,\n                        objective='regression',random_state=0) \ncb_reg1 = CatBoostRegressor(task_type='GPU',random_state=0,\n                             iterations=1000,verbose=False)\nreg_tabnet = NNWrapper(TabNetRegressor(verbose=0,seed=0),StandardScaler(),max_epochs=100, patience=150,\n                       X_valid=np.array(features_val), y_valid = np.array(labels_val).reshape(-1, 1))\nclf_cb_1 = CatBoostClassifier(task_type='GPU',random_state=0, loss_function='MultiClass',\n                                auto_class_weights=\"Balanced\",iterations=1000,verbose=False)\nclf_lr = LMWrapper(LogisticRegression(multi_class=\"multinomial\",class_weight=\"balanced\",\n                                        C=1e-1,max_iter=300,random_state=0),StandardScaler())\nclf_nb1 =  BernoulliNB(alpha=1,binarize=0.3)","execution_count":11,"outputs":[{"output_type":"stream","text":"Device used : cuda\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Работа стекинга, проверка на валидационной части выборки. Важно отметить, что здесь я обучаю метаалгоритм на объединенной выборке, то есть склеиваю исходную выборку и новые признаки, полученные с помощью предсказаний базовых алгоритмов. Если посмотреть на класс стекинга, представленный выше, можно заметить главную проблему данной схемы - метаалгоритм обучается на небольшой доле объектов. "},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nwarnings.filterwarnings(\"ignore\")\nmodels = [ls0,knn1, knn2,rf2,gbm1,cb_reg1,\n           reg_tabnet,clf_cb_1,clf_nb1,clf_lr]\n\nmeta_model = CatBoostClassifier(task_type='GPU',random_state=0, loss_function='MultiClassOneVsAll',\n                                auto_class_weights=\"Balanced\",iterations=1000,verbose=False)\n\nstack = Stacking(models, meta_model,merge=True)\nstack.fit(features_train,np.array(labels_train).reshape(-1, 1),p=0.2,random_state=0)# сложно из-за нейросети\npreds = stack.predict(features_val)\nprint(classification_report(labels_val,preds))\nprint(\"------\")\nprint(f\"Macro f1 score: {f1_score(labels_val,preds,average='macro')}\")","execution_count":12,"outputs":[{"output_type":"stream","text":"Ok 0\nOk 1\nOk 2\nOk 3\nOk 4\nOk 5\nOk 6\nOk 7\nOk 8\nOk 9\n------\nOk\n------\nPrediction\nOk0\nOk1\nOk2\nOk3\nOk4\nOk5\nOk6\nOk7\nOk8\nOk9\n              precision    recall  f1-score   support\n\n           0       0.80      0.77      0.79      5212\n           1       0.36      0.35      0.35      1695\n           2       0.41      0.60      0.48       450\n\n    accuracy                           0.67      7357\n   macro avg       0.52      0.58      0.54      7357\nweighted avg       0.68      0.67      0.67      7357\n\n------\nMacro f1 score: 0.5421054121419754\nCPU times: user 8min 44s, sys: 24.9 s, total: 9min 9s\nWall time: 8min 54s\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Видно, что качество на валидации достаточно высокое, но я подбирал модель на кросс-валидации, что потребовало гораздо большего времени, но позволило оценить среднее значение метрики и ее дисперсию.\n\nСреднее было около 0.538,min около 0.525,max около 0.545. (кросс-валидацию проводил несколько раз, поэтому все попытки не сохранились:(, пишу что вспомнил)"},{"metadata":{},"cell_type":"markdown","source":"**Результаты в соревновании:**\n\nPublic score: **0.52940**\n\nPrivate score: **0.54105**"},{"metadata":{},"cell_type":"markdown","source":"Мой итоговый результат является результатом усреднения 2-х таких стекингов (во втором моделей 15 и они немного сложнее) и нескольких попыток CatBoost. Про подбор CatBoost на кросс-валидации сделаю отдельный ноутбук. Всем удачи!"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}