{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Inference with Roberta large\nby Artyom Glazunov","metadata":{}},{"cell_type":"markdown","source":"Here you can find an example of the inference using Roberta large model. The tokenizer and initial model are loaded from https://www.kaggle.com/artemglazunov1990/roberta-save, a finetuned model you can load from your notebook (one example you can find here https://www.kaggle.com/artemglazunov1990/transfer-learning-with-roberta-large). To do that you can load outputs of your notebook with saved models in the inference notebook as an input (to save the model you can simply save its state_dict (https://pytorch.org/tutorials/beginner/saving_loading_models.html) and then load it as it is done here). ","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-16T17:25:33.386795Z","iopub.execute_input":"2021-07-16T17:25:33.387199Z","iopub.status.idle":"2021-07-16T17:25:33.417576Z","shell.execute_reply.started":"2021-07-16T17:25:33.38712Z","shell.execute_reply":"2021-07-16T17:25:33.416673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%bash\ncp ../input/roberta-save/rob.zip .\ncp ../input/roberta-save/rob_tok.zip .\nunzip rob.zip\nunzip rob_tok.zip \nrm -r rob.zip rob_tok.zip ","metadata":{"execution":{"iopub.status.busy":"2021-07-16T17:25:33.418905Z","iopub.execute_input":"2021-07-16T17:25:33.419286Z","iopub.status.idle":"2021-07-16T17:26:01.575278Z","shell.execute_reply.started":"2021-07-16T17:25:33.419251Z","shell.execute_reply":"2021-07-16T17:26:01.574187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom transformers import RobertaTokenizer, RobertaModel\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader\nimport gc","metadata":{"execution":{"iopub.status.busy":"2021-07-16T17:26:01.586164Z","iopub.execute_input":"2021-07-16T17:26:01.586444Z","iopub.status.idle":"2021-07-16T17:26:09.177685Z","shell.execute_reply.started":"2021-07-16T17:26:01.586412Z","shell.execute_reply":"2021-07-16T17:26:09.176875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Load test data","metadata":{}},{"cell_type":"code","source":"df_test = pd.read_csv('/kaggle/input/commonlitreadabilityprize/test.csv')\ndf_test","metadata":{"execution":{"iopub.status.busy":"2021-07-16T17:26:09.291144Z","iopub.execute_input":"2021-07-16T17:26:09.291556Z","iopub.status.idle":"2021-07-16T17:26:09.310304Z","shell.execute_reply.started":"2021-07-16T17:26:09.291517Z","shell.execute_reply":"2021-07-16T17:26:09.309577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_test = df_test['excerpt'].values\nind_test = df_test['id'].values\ndata_test[0], ind_test[0]","metadata":{"execution":{"iopub.status.busy":"2021-07-16T17:26:09.311374Z","iopub.execute_input":"2021-07-16T17:26:09.311714Z","iopub.status.idle":"2021-07-16T17:26:09.317719Z","shell.execute_reply.started":"2021-07-16T17:26:09.311681Z","shell.execute_reply":"2021-07-16T17:26:09.31684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ind_test[df_test.index]","metadata":{"execution":{"iopub.status.busy":"2021-07-16T17:26:09.321167Z","iopub.execute_input":"2021-07-16T17:26:09.321802Z","iopub.status.idle":"2021-07-16T17:26:09.328505Z","shell.execute_reply.started":"2021-07-16T17:26:09.321763Z","shell.execute_reply":"2021-07-16T17:26:09.327489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Load the tokenizer from another notebook's output","metadata":{}},{"cell_type":"code","source":"tokenizer = RobertaTokenizer.from_pretrained(\n    'rob_tok'\n)","metadata":{"execution":{"iopub.status.busy":"2021-07-16T17:26:09.33077Z","iopub.execute_input":"2021-07-16T17:26:09.331211Z","iopub.status.idle":"2021-07-16T17:26:09.415472Z","shell.execute_reply.started":"2021-07-16T17:26:09.331171Z","shell.execute_reply":"2021-07-16T17:26:09.414683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Prepare our data for the Roberta input","metadata":{}},{"cell_type":"code","source":"encoded_data_test = tokenizer.batch_encode_plus(\n    data_test,\n    add_special_tokens=True,\n    return_attention_mask=True,\n    pad_to_max_length=True,\n    max_length=512,\n    return_tensors='pt'\n)\n\ninput_ids_test = encoded_data_test['input_ids']\nattention_masks_test = encoded_data_test['attention_mask']\nids_test_tensor = torch.tensor(df_test.index, dtype=torch.float)","metadata":{"execution":{"iopub.status.busy":"2021-07-16T17:26:09.417577Z","iopub.execute_input":"2021-07-16T17:26:09.418154Z","iopub.status.idle":"2021-07-16T17:26:10.512269Z","shell.execute_reply.started":"2021-07-16T17:26:09.418114Z","shell.execute_reply":"2021-07-16T17:26:10.511465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_test = TensorDataset(input_ids_test,\n                            attention_masks_test,\n                            ids_test_tensor)","metadata":{"execution":{"iopub.status.busy":"2021-07-16T17:26:10.513463Z","iopub.execute_input":"2021-07-16T17:26:10.514022Z","iopub.status.idle":"2021-07-16T17:26:10.519519Z","shell.execute_reply.started":"2021-07-16T17:26:10.513969Z","shell.execute_reply":"2021-07-16T17:26:10.518655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 8\n\ndataloader_test = DataLoader(\n    dataset_test,\n    batch_size=batch_size,\n    shuffle = False\n)","metadata":{"execution":{"iopub.status.busy":"2021-07-16T17:26:10.520879Z","iopub.execute_input":"2021-07-16T17:26:10.521245Z","iopub.status.idle":"2021-07-16T17:26:10.529564Z","shell.execute_reply.started":"2021-07-16T17:26:10.521194Z","shell.execute_reply":"2021-07-16T17:26:10.528655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Our GPU device to use Roberta on","metadata":{}},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{"execution":{"iopub.status.busy":"2021-07-16T17:26:10.530899Z","iopub.execute_input":"2021-07-16T17:26:10.5313Z","iopub.status.idle":"2021-07-16T17:26:10.581519Z","shell.execute_reply.started":"2021-07-16T17:26:10.531261Z","shell.execute_reply":"2021-07-16T17:26:10.580735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Our model class, it uses pretrained initial Roberta model","metadata":{}},{"cell_type":"code","source":"class BERTRegressor(torch.nn.Module): \n    def __init__(self, pretrained_src = 'rob'): \n        super().__init__()\n        self.bert = RobertaModel.from_pretrained(pretrained_src)\n        self.linear = torch.nn.Linear(1024, 1)\n        self.dropout = torch.nn.Dropout(0.15)\n        \n    def forward(self, input_ids, attention_mask): #x - tokenized batch\n        hidden = self.bert(input_ids, \n                           attention_mask=attention_mask)[0][:, 0, :]#CLS token output                                                          \n        output = self.linear(self.dropout(hidden))\n        return output\n","metadata":{"execution":{"iopub.status.busy":"2021-07-16T17:26:10.583035Z","iopub.execute_input":"2021-07-16T17:26:10.583421Z","iopub.status.idle":"2021-07-16T17:26:10.59242Z","shell.execute_reply.started":"2021-07-16T17:26:10.583385Z","shell.execute_reply":"2021-07-16T17:26:10.591623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Load our finetuned state dict from another notebook","metadata":{}},{"cell_type":"code","source":"model = BERTRegressor()\nPATH = '...' #here will be you path to the model's state dict\nmodel.load_state_dict(torch.load(PATH), strict=False)\nmodel.to(device);","metadata":{"execution":{"iopub.status.busy":"2021-07-16T17:26:10.593958Z","iopub.execute_input":"2021-07-16T17:26:10.594346Z","iopub.status.idle":"2021-07-16T17:26:36.749969Z","shell.execute_reply.started":"2021-07-16T17:26:10.594308Z","shell.execute_reply":"2021-07-16T17:26:36.749093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's define our function for prediction","metadata":{}},{"cell_type":"code","source":"def predict(dataloader_test, model):\n\n    model.eval()\n    \n    predictions, indices_all = [], []\n    \n    for batch in tqdm.notebook.tqdm(dataloader_test):\n        \n        batch = tuple(b.to(device) for b in batch)\n        \n        inputs = {'input_ids':      batch[0],\n                  'attention_mask': batch[1]\n        }\n        indices_batch = batch[2].cpu().numpy()\n\n        with torch.no_grad():        \n            output = model(**inputs)\n            \n        output = output.detach().cpu().numpy()\n        predictions.append(output)\n        indices_all.append(indices_batch)    \n      \n    predictions = np.concatenate(predictions, axis=0)\n    indices = np.concatenate(indices_all, axis=0)\n            \n    return predictions, indices.astype(int)","metadata":{"execution":{"iopub.status.busy":"2021-07-16T17:27:02.546754Z","iopub.execute_input":"2021-07-16T17:27:02.547137Z","iopub.status.idle":"2021-07-16T17:27:02.556801Z","shell.execute_reply.started":"2021-07-16T17:27:02.547098Z","shell.execute_reply":"2021-07-16T17:27:02.555712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions, indices = predict(dataloader_test, model)  ","metadata":{"execution":{"iopub.status.busy":"2021-07-16T17:27:02.558301Z","iopub.execute_input":"2021-07-16T17:27:02.558738Z","iopub.status.idle":"2021-07-16T17:27:02.983266Z","shell.execute_reply.started":"2021-07-16T17:27:02.558695Z","shell.execute_reply":"2021-07-16T17:27:02.98205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions, indices","metadata":{"execution":{"iopub.status.busy":"2021-07-16T17:27:02.984776Z","iopub.execute_input":"2021-07-16T17:27:02.985157Z","iopub.status.idle":"2021-07-16T17:27:02.995719Z","shell.execute_reply.started":"2021-07-16T17:27:02.985116Z","shell.execute_reply":"2021-07-16T17:27:02.994501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Clear the memory","metadata":{}},{"cell_type":"code","source":"model.cpu();\ndel model\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-07-16T17:27:02.99709Z","iopub.execute_input":"2021-07-16T17:27:02.997485Z","iopub.status.idle":"2021-07-16T17:27:04.127215Z","shell.execute_reply.started":"2021-07-16T17:27:02.997449Z","shell.execute_reply":"2021-07-16T17:27:04.126357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Final submission","metadata":{}},{"cell_type":"code","source":"ids = pd.DataFrame(ind_test[indices],columns=['id'])['id']","metadata":{"execution":{"iopub.status.busy":"2021-07-16T17:29:01.207019Z","iopub.execute_input":"2021-07-16T17:29:01.207353Z","iopub.status.idle":"2021-07-16T17:29:01.212169Z","shell.execute_reply.started":"2021-07-16T17:29:01.207318Z","shell.execute_reply":"2021-07-16T17:29:01.211039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df = pd.DataFrame(predictions, index=ids,\n                      columns = ['target'])\nsub_df","metadata":{"execution":{"iopub.status.busy":"2021-07-16T17:29:04.39359Z","iopub.execute_input":"2021-07-16T17:29:04.393944Z","iopub.status.idle":"2021-07-16T17:29:04.404348Z","shell.execute_reply.started":"2021-07-16T17:29:04.393909Z","shell.execute_reply":"2021-07-16T17:29:04.403106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df.to_csv('submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-07-16T17:29:18.450368Z","iopub.execute_input":"2021-07-16T17:29:18.450688Z","iopub.status.idle":"2021-07-16T17:29:18.707341Z","shell.execute_reply.started":"2021-07-16T17:29:18.450657Z","shell.execute_reply":"2021-07-16T17:29:18.706558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!rm -r rob rob_tok","metadata":{"execution":{"iopub.status.busy":"2021-07-16T17:23:46.16585Z","iopub.status.idle":"2021-07-16T17:23:46.166796Z"},"trusted":true},"execution_count":null,"outputs":[]}]}